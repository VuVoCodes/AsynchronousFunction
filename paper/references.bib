% References

@inproceedings{wang2020makes,
  title={What makes training multi-modal classification networks hard?},
  author={Wang, Weiyao and Tran, Du and Feiszli, Matt},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12695--12705},
  year={2020}
}

@inproceedings{peng2022balanced,
  title={Balanced multimodal learning via on-the-fly gradient modulation},
  author={Peng, Xiaokang and Wei, Yake and Deng, Andong and Wang, Dong and Hu, Di},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={8238--8247},
  year={2022}
}

@inproceedings{li2023boosting,
  title={Boosting multi-modal model performance with adaptive gradient modulation},
  author={Li, Hong and Li, Xingyu and Hu, Pengbo and Lei, Yinuo and Li, Chunxiao and Zhou, Yi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={22214--22224},
  year={2023}
}

@inproceedings{fan2023pmr,
  title={PMR: Prototypical modal rebalance for multimodal learning},
  author={Fan, Yunfeng and Xu, Wenchao and Wang, Haozhao and Wang, Junxiao and Guo, Song},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={20029--20038},
  year={2023}
}

@article{wei2024mmpareto,
  title={MMPareto: Boosting multimodal learning with innocent unimodal assistance},
  author={Wei, Yake and Hu, Di},
  journal={arXiv preprint arXiv:2405.17730},
  year={2024}
}

@article{zhang2023mla,
  title={Multimodal representation learning by alternating unimodal adaptation},
  author={Zhang, Xiaohui and Yoon, Jaehong and Bansal, Mohit and Yao, Huaxiu},
  journal={arXiv preprint arXiv:2311.10707},
  year={2023}
}

@inproceedings{wei2025diagnosing,
  title={Diagnosing and re-learning for balanced multimodal learning},
  author={Wei, Yake and Li, Siwei and Feng, Ruoxuan and Hu, Di},
  booktitle={European Conference on Computer Vision},
  pages={71--86},
  year={2025}
}

@inproceedings{wei2025improving,
  title={Improving Multimodal Learning via Imbalanced Learning},
  author={Wei, Shicai and Luo, Chunbo and Luo, Yang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  year={2025}
}

@inproceedings{cao2014crema,
  title={Crema-d: Crowd-sourced emotional multimodal actors dataset},
  author={Cao, Houwei and Cooper, David G and Keutmann, Michael K and Gur, Ruben C and Nenkova, Ani and Verma, Ragini},
  booktitle={IEEE transactions on affective computing},
  volume={5},
  number={4},
  pages={377--390},
  year={2014}
}

@inproceedings{tian2018audio,
  title={Audio-visual event localization in unconstrained videos},
  author={Tian, Yapeng and Shi, Jing and Li, Bochen and Duan, Zhiyao and Xu, Chenliang},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={247--263},
  year={2018}
}

@inproceedings{arandjelovic2017look,
  title={Look, listen and learn},
  author={Arandjelovic, Relja and Zisserman, Andrew},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={609--617},
  year={2017}
}
